<?xml version="1.0"?>
<clickhouse>
    <!-- ClickHouse Analytics Cluster Configuration -->
    
    <!-- Logging Configuration -->
    <logger>
        <level>information</level>
        <log>/var/log/clickhouse-server/clickhouse-server.log</log>
        <errorlog>/var/log/clickhouse-server/clickhouse-server.err.log</errorlog>
        <size>1000M</size>
        <count>10</count>
    </logger>

    <!-- HTTP Server Configuration -->
    <http_port>8123</http_port>
    <tcp_port>9000</tcp_port>
    <mysql_port>9004</mysql_port>
    <postgresql_port>9005</postgresql_port>

    <!-- Listen on all interfaces -->
    <listen_host>::</listen_host>
    <listen_host>0.0.0.0</listen_host>

    <!-- Maximum connections -->
    <max_connections>4096</max_connections>
    <keep_alive_timeout>3</keep_alive_timeout>
    <max_concurrent_queries>100</max_concurrent_queries>

    <!-- Memory and Performance Settings -->
    <max_server_memory_usage_to_ram_ratio>0.8</max_server_memory_usage_to_ram_ratio>
    <max_memory_usage>10000000000</max_memory_usage>
    <use_uncompressed_cache>1</use_uncompressed_cache>
    <uncompressed_cache_size>8589934592</uncompressed_cache_size>
    <mark_cache_size>5368709120</mark_cache_size>

    <!-- Storage Configuration -->
    <storage_configuration>
        <disks>
            <default>
                <path>/var/lib/clickhouse/</path>
            </default>
            <hot>
                <path>/var/lib/clickhouse/hot/</path>
            </hot>
            <cold>
                <path>/var/lib/clickhouse/cold/</path>
            </cold>
            <archive>
                <path>/var/lib/clickhouse/archive/</path>
            </archive>
        </disks>
        
        <policies>
            <default>
                <volumes>
                    <hot>
                        <disk>hot</disk>
                        <max_data_part_size_bytes>10737418240</max_data_part_size_bytes>
                    </hot>
                    <cold>
                        <disk>cold</disk>
                        <max_data_part_size_bytes>107374182400</max_data_part_size_bytes>
                    </cold>
                </volumes>
                <move_factor>0.1</move_factor>
            </default>
            
            <cold_storage>
                <volumes>
                    <archive>
                        <disk>archive</disk>
                    </archive>
                </volumes>
            </cold_storage>
        </policies>
    </storage_configuration>

    <!-- Cluster Configuration -->
    <remote_servers>
        <bilten_cluster>
            <shard>
                <replica>
                    <host>clickhouse</host>
                    <port>9000</port>
                </replica>
            </shard>
        </bilten_cluster>
    </remote_servers>

    <!-- Zookeeper Configuration (for replication) -->
    <zookeeper>
        <node index="1">
            <host>zookeeper</host>
            <port>2181</port>
        </node>
    </zookeeper>

    <!-- Macros for replication -->
    <macros>
        <shard>01</shard>
        <replica>replica_1</replica>
    </macros>

    <!-- Users and Access Control -->
    <users>
        <default>
            <password></password>
            <networks incl="networks" replace="replace">
                <ip>::/0</ip>
            </networks>
            <profile>default</profile>
            <quota>default</quota>
        </default>
        
        <bilten_user>
            <password>bilten_password</password>
            <networks>
                <ip>::/0</ip>
            </networks>
            <profile>default</profile>
            <quota>default</quota>
            <databases>
                <database>bilten_analytics</database>
                <database>bilten_analytics_archive</database>
            </databases>
        </bilten_user>
    </users>

    <!-- Profiles -->
    <profiles>
        <default>
            <max_memory_usage>10000000000</max_memory_usage>
            <use_uncompressed_cache>1</use_uncompressed_cache>
            <load_balancing>random</load_balancing>
            <max_execution_time>300</max_execution_time>
            <max_rows_to_read>1000000000</max_rows_to_read>
            <max_bytes_to_read>100000000000</max_bytes_to_read>
        </default>
        
        <analytics>
            <max_memory_usage>20000000000</max_memory_usage>
            <max_execution_time>600</max_execution_time>
            <max_rows_to_read>10000000000</max_rows_to_read>
            <max_bytes_to_read>1000000000000</max_bytes_to_read>
        </analytics>
    </profiles>

    <!-- Quotas -->
    <quotas>
        <default>
            <interval>
                <duration>3600</duration>
                <queries>0</queries>
                <errors>0</errors>
                <result_rows>0</result_rows>
                <read_rows>0</read_rows>
                <execution_time>0</execution_time>
            </interval>
        </default>
    </quotas>

    <!-- Compression Settings -->
    <compression incl="compression">
        <case>
            <method>zstd</method>
            <level>3</level>
        </case>
    </compression>

    <!-- Query Log -->
    <query_log>
        <database>system</database>
        <table>query_log</table>
        <partition_by>toYYYYMM(event_date)</partition_by>
        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
    </query_log>

    <!-- Part Log -->
    <part_log>
        <database>system</database>
        <table>part_log</table>
        <partition_by>toYYYYMM(event_date)</partition_by>
        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
    </part_log>

    <!-- Merge Tree Settings -->
    <merge_tree>
        <max_suspicious_broken_parts>5</max_suspicious_broken_parts>
        <parts_to_delay_insert>1000</parts_to_delay_insert>
        <parts_to_throw_insert>3000</parts_to_throw_insert>
        <max_parts_in_total>10000</max_parts_in_total>
        <merge_with_ttl_timeout>3600</merge_with_ttl_timeout>
    </merge_tree>

    <!-- Kafka Integration -->
    <kafka>
        <auto_offset_reset>smallest</auto_offset_reset>
        <enable_auto_commit>true</enable_auto_commit>
        <auto_commit_interval_ms>5000</auto_commit_interval_ms>
    </kafka>

    <!-- Distributed DDL -->
    <distributed_ddl>
        <path>/clickhouse/task_queue/ddl</path>
    </distributed_ddl>

    <!-- Format Schema Path -->
    <format_schema_path>/var/lib/clickhouse/format_schemas/</format_schema_path>
</clickhouse>